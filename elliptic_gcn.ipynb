{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8165e6ff",
   "metadata": {},
   "source": [
    "# Experiment 1: Random 70-30 Split\n",
    "\n",
    "Baseline experiment with stratified random split:\n",
    "- 70% of labeled data for training\n",
    "- 30% of labeled data for testing\n",
    "- Stratified split maintains class distribution\n",
    "- Uses class weights to handle imbalance (9.8% illicit vs 90.2% licit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6bc08763",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "classes_df = pd.read_csv(\"raw_data/elliptic_bitcoin_dataset/elliptic_txs_classes.csv\")\n",
    "edgelist_df = pd.read_csv(\"raw_data/elliptic_bitcoin_dataset/elliptic_txs_edgelist.csv\")\n",
    "features_df = pd.read_csv(\"raw_data/elliptic_bitcoin_dataset/elliptic_txs_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "37dstr5ch1h",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "g74cyqri607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 203768\n",
      "Number of features: 166\n",
      "Number of edges: 234353\n",
      "Label distribution: Unknown=157204, Illicit=4545, Licit=42019\n"
     ]
    }
   ],
   "source": [
    "# Prepare node features\n",
    "features = features_df.iloc[:, 1:].values\n",
    "node_ids = features_df.iloc[:, 0].values\n",
    "\n",
    "# Create node ID to index mapping\n",
    "node_id_to_idx = {node_id: idx for idx, node_id in enumerate(node_ids)}\n",
    "\n",
    "# Prepare labels - CORRECT MAPPING: '1'=illicit, '2'=licit\n",
    "# Map to: 0=unknown, 1=illicit, 2=licit\n",
    "classes_df['class'] = classes_df['class'].map({'unknown': 0, '1': 1, '2': 2})\n",
    "labels = np.zeros(len(node_ids), dtype=int)\n",
    "for _, row in classes_df.iterrows():\n",
    "    if row['txId'] in node_id_to_idx:\n",
    "        labels[node_id_to_idx[row['txId']]] = row['class']\n",
    "\n",
    "# Prepare edge index\n",
    "edge_list = []\n",
    "for _, row in edgelist_df.iterrows():\n",
    "    if row['txId1'] in node_id_to_idx and row['txId2'] in node_id_to_idx:\n",
    "        edge_list.append([node_id_to_idx[row['txId1']], node_id_to_idx[row['txId2']]])\n",
    "\n",
    "edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x = torch.tensor(features, dtype=torch.float)\n",
    "y = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "print(f\"Number of nodes: {x.shape[0]}\")\n",
    "print(f\"Number of features: {x.shape[1]}\")\n",
    "print(f\"Number of edges: {edge_index.shape[1]}\")\n",
    "print(f\"Label distribution: Unknown={sum(y==0)}, Illicit={sum(y==1)}, Licit={sum(y==2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "htsyjlidomt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training nodes: 32594\n",
      "Test nodes: 13970\n",
      "Unknown nodes: 157204\n"
     ]
    }
   ],
   "source": [
    "# Create train/test split (only on labeled nodes)\n",
    "labeled_mask = y > 0\n",
    "labeled_indices = torch.where(labeled_mask)[0].numpy()\n",
    "\n",
    "train_indices, test_indices = train_test_split(\n",
    "    labeled_indices, \n",
    "    test_size=0.3, \n",
    "    random_state=42, \n",
    "    stratify=y[labeled_indices].numpy()\n",
    ")\n",
    "\n",
    "# Create masks\n",
    "train_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "test_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "train_mask[train_indices] = True\n",
    "test_mask[test_indices] = True\n",
    "\n",
    "print(f\"Training nodes: {train_mask.sum()}\")\n",
    "print(f\"Test nodes: {test_mask.sum()}\")\n",
    "print(f\"Unknown nodes: {(~labeled_mask).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eaw4l85x6th",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCNFraudDetector(\n",
      "  (gcn1): GCNConv(166, 64)\n",
      "  (gcn2): GCNConv(64, 32)\n",
      "  (fc): Linear(in_features=32, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class GCNFraudDetector(torch.nn.Module):\n",
    "    def __init__(self, in_features=166, hidden=64, out_classes=3, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.gcn1 = GCNConv(in_features, hidden)\n",
    "        self.gcn2 = GCNConv(hidden, hidden // 2)\n",
    "        self.fc = torch.nn.Linear(hidden // 2, out_classes)\n",
    "        self.dropout = dropout\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        # GCN Layer 1\n",
    "        x = self.gcn1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "        # GCN Layer 2\n",
    "        x = self.gcn2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "        # Output layer\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = GCNFraudDetector(in_features=x.shape[1], hidden=64, out_classes=3, dropout=0.5)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9ei64meng9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "Class distribution in training set:\n",
      "  Class 1 (Illicit):  3181 samples (9.8%)\n",
      "  Class 2 (Licit):    29413 samples (90.2%)\n",
      "\n",
      "Class weights:\n",
      "  Class 0 (Unknown): 1.0000 (not used in training)\n",
      "  Class 1 (Illicit):  5.1232\n",
      "  Class 2 (Licit):    0.5541\n",
      "\n",
      "Weight ratio (Illicit/Licit): 9.25x\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "x = x.to(device)\n",
    "edge_index = edge_index.to(device)\n",
    "y = y.to(device)\n",
    "train_mask = train_mask.to(device)\n",
    "test_mask = test_mask.to(device)\n",
    "\n",
    "# Calculate class weights to handle imbalance\n",
    "# Only consider labeled classes (1=illicit, 2=licit) since class 0 (unknown) is not in training\n",
    "train_labels = y[train_mask]\n",
    "n_illicit = (train_labels == 1).sum().float()\n",
    "n_licit = (train_labels == 2).sum().float()\n",
    "total = train_labels.shape[0]\n",
    "\n",
    "# Compute weights: inversely proportional to class frequency\n",
    "# We need weights for all 3 classes (0, 1, 2) even though 0 is not in training\n",
    "weight_illicit = total / (2.0 * n_illicit)  # Higher weight for minority class\n",
    "weight_licit = total / (2.0 * n_licit)      # Lower weight for majority class\n",
    "class_weights = torch.tensor([1.0, weight_illicit, weight_licit], dtype=torch.float).to(device)\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"\\nClass distribution in training set:\")\n",
    "print(f\"  Class 1 (Illicit):  {n_illicit.int()} samples ({n_illicit/total*100:.1f}%)\")\n",
    "print(f\"  Class 2 (Licit):    {n_licit.int()} samples ({n_licit/total*100:.1f}%)\")\n",
    "print(f\"\\nClass weights:\")\n",
    "print(f\"  Class 0 (Unknown): {class_weights[0]:.4f} (not used in training)\")\n",
    "print(f\"  Class 1 (Illicit):  {class_weights[1]:.4f}\")\n",
    "print(f\"  Class 2 (Licit):    {class_weights[2]:.4f}\")\n",
    "print(f\"\\nWeight ratio (Illicit/Licit): {class_weights[1]/class_weights[2]:.2f}x\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "sbyokj19bx",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GCN...\n",
      "Epoch 010, Loss: 0.5411, Train Acc: 0.8127, Test Acc: 0.8134\n",
      "Epoch 020, Loss: 0.4826, Train Acc: 0.8168, Test Acc: 0.8169\n",
      "Epoch 030, Loss: 0.4240, Train Acc: 0.8490, Test Acc: 0.8477\n",
      "Epoch 040, Loss: 0.3980, Train Acc: 0.8715, Test Acc: 0.8709\n",
      "Epoch 050, Loss: 0.3689, Train Acc: 0.8719, Test Acc: 0.8731\n",
      "\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(x, edge_index)\n",
    "    loss = criterion(out[train_mask], y[train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(mask):\n",
    "    model.eval()\n",
    "    out = model(x, edge_index)\n",
    "    pred = out.argmax(dim=1)\n",
    "    correct = pred[mask] == y[mask]\n",
    "    acc = int(correct.sum()) / int(mask.sum())\n",
    "    return acc, pred[mask].cpu(), out[mask].cpu()\n",
    "\n",
    "# Training loop\n",
    "print(\"Training GCN...\")\n",
    "for epoch in range(1, 51):\n",
    "    loss = train()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        train_acc, _, _ = test(train_mask)\n",
    "        test_acc, _, _ = test(test_mask)\n",
    "        print(f'Epoch {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "pyzccecndg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "FINAL EVALUATION METRICS\n",
      "==================================================\n",
      "Accuracy:  87.31%\n",
      "Precision: 42.42%\n",
      "Recall:    83.94%\n",
      "F1 Score:  56.36%\n",
      "AUC-ROC:   0.9408\n",
      "PR-AUC:    0.7212\n",
      "RMSE:      0.3563\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation\n",
    "_, test_pred, test_out = test(test_mask)\n",
    "test_labels = y[test_mask].cpu().numpy()\n",
    "\n",
    "# Convert to binary classification (0=licit, 1=illicit)\n",
    "# Model outputs: 0=unknown, 1=illicit, 2=licit\n",
    "binary_pred = (test_pred.numpy() == 1).astype(int)  # 1 if illicit, 0 otherwise\n",
    "binary_labels = (test_labels == 1).astype(int)  # 1 if illicit, 0 otherwise\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(binary_labels, binary_pred)\n",
    "precision = precision_score(binary_labels, binary_pred, zero_division=0)\n",
    "recall = recall_score(binary_labels, binary_pred, zero_division=0)\n",
    "f1 = f1_score(binary_labels, binary_pred, zero_division=0)\n",
    "\n",
    "# Get probabilities for AUC-ROC and PR-AUC (probability of illicit class)\n",
    "test_probs = F.softmax(test_out, dim=1)[:, 1].numpy()  # Column 1 = illicit\n",
    "auc_roc = roc_auc_score(binary_labels, test_probs)\n",
    "pr_auc = average_precision_score(binary_labels, test_probs)\n",
    "\n",
    "# RMSE\n",
    "rmse = np.sqrt(mean_squared_error(binary_labels, binary_pred))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL EVALUATION METRICS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Accuracy:  {accuracy*100:.2f}%\")\n",
    "print(f\"Precision: {precision*100:.2f}%\")\n",
    "print(f\"Recall:    {recall*100:.2f}%\")\n",
    "print(f\"F1 Score:  {f1*100:.2f}%\")\n",
    "print(f\"AUC-ROC:   {auc_roc:.4f}\")\n",
    "print(f\"PR-AUC:    {pr_auc:.4f}\")\n",
    "print(f\"RMSE:      {rmse:.4f}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d2jxp9wb",
   "metadata": {},
   "source": [
    "# Experiment 2: Temporal 80-20 Split\n",
    "\n",
    "Instead of random split, we now split based on time steps (column 2 in features).\n",
    "- Time steps range from 1 to 49 (about 2-week intervals)\n",
    "- Train on first 80% of time steps (1-39)\n",
    "- Test on last 20% of time steps (40-49)\n",
    "- This simulates real-world scenario: train on past data, predict future transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "npjq9eam9ls",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step analysis:\n",
      "  Time step range: 1 to 49\n",
      "  Unique time steps: 49\n",
      "  Time step distribution:\n",
      "    Time step  1:  7879 nodes (2147 labeled)\n",
      "    Time step  2:  4544 nodes (1117 labeled)\n",
      "    Time step  3:  6621 nodes (1279 labeled)\n",
      "    Time step  4:  5693 nodes (1440 labeled)\n",
      "    Time step  5:  6803 nodes (1882 labeled)\n",
      "    Time step  6:  4328 nodes ( 485 labeled)\n",
      "    Time step  7:  6048 nodes (1203 labeled)\n",
      "    Time step  8:  4457 nodes (1165 labeled)\n",
      "    Time step  9:  4996 nodes ( 778 labeled)\n",
      "    Time step 10:  6727 nodes ( 972 labeled)\n",
      "    Time step 11:  4296 nodes ( 696 labeled)\n",
      "    Time step 12:  2047 nodes ( 506 labeled)\n",
      "    Time step 13:  4528 nodes ( 809 labeled)\n",
      "    Time step 14:  2022 nodes ( 417 labeled)\n",
      "    Time step 15:  3639 nodes ( 618 labeled)\n",
      "    Time step 16:  2975 nodes ( 530 labeled)\n",
      "    Time step 17:  3385 nodes ( 811 labeled)\n",
      "    Time step 18:  1976 nodes ( 389 labeled)\n",
      "    Time step 19:  3506 nodes ( 745 labeled)\n",
      "    Time step 20:  4291 nodes ( 900 labeled)\n",
      "    Time step 21:  3537 nodes ( 641 labeled)\n",
      "    Time step 22:  5894 nodes (1763 labeled)\n",
      "    Time step 23:  4165 nodes (1187 labeled)\n",
      "    Time step 24:  4592 nodes (1126 labeled)\n",
      "    Time step 25:  2314 nodes ( 594 labeled)\n",
      "    Time step 26:  2523 nodes ( 517 labeled)\n",
      "    Time step 27:  1089 nodes ( 206 labeled)\n",
      "    Time step 28:  1653 nodes ( 284 labeled)\n",
      "    Time step 29:  4275 nodes (1174 labeled)\n",
      "    Time step 30:  2483 nodes ( 524 labeled)\n",
      "    Time step 31:  2816 nodes ( 710 labeled)\n",
      "    Time step 32:  4525 nodes (1323 labeled)\n",
      "    Time step 33:  3151 nodes ( 441 labeled)\n",
      "    Time step 34:  2486 nodes ( 515 labeled)\n",
      "    Time step 35:  5507 nodes (1341 labeled)\n",
      "    Time step 36:  6393 nodes (1708 labeled)\n",
      "    Time step 37:  3306 nodes ( 498 labeled)\n",
      "    Time step 38:  2891 nodes ( 756 labeled)\n",
      "    Time step 39:  2760 nodes (1183 labeled)\n",
      "    Time step 40:  4481 nodes (1211 labeled)\n",
      "    Time step 41:  5342 nodes (1132 labeled)\n",
      "    Time step 42:  7140 nodes (2154 labeled)\n",
      "    Time step 43:  5063 nodes (1370 labeled)\n",
      "    Time step 44:  4975 nodes (1591 labeled)\n",
      "    Time step 45:  5598 nodes (1221 labeled)\n",
      "    Time step 46:  3519 nodes ( 712 labeled)\n",
      "    Time step 47:  5121 nodes ( 846 labeled)\n",
      "    Time step 48:  2954 nodes ( 471 labeled)\n",
      "    Time step 49:  2454 nodes ( 476 labeled)\n"
     ]
    }
   ],
   "source": [
    "# Extract time steps (column 1, 0-indexed) from features_df\n",
    "time_steps = features_df.iloc[:, 1].values\n",
    "\n",
    "# Create mapping from node_id to time step\n",
    "time_step_map = {}\n",
    "for idx, node_id in enumerate(node_ids):\n",
    "    time_step_map[node_id] = time_steps[idx]\n",
    "\n",
    "print(\"Time step analysis:\")\n",
    "print(f\"  Time step range: {time_steps.min()} to {time_steps.max()}\")\n",
    "print(f\"  Unique time steps: {len(np.unique(time_steps))}\")\n",
    "print(f\"  Time step distribution:\")\n",
    "for ts in sorted(np.unique(time_steps)):\n",
    "    count = sum(time_steps == ts)\n",
    "    labeled_count = sum((time_steps == ts) & (labels > 0))\n",
    "    print(f\"    Time step {ts:2d}: {count:5d} nodes ({labeled_count:4d} labeled)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6s6lzvr5of",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal split at time step 39\n",
      "  Training: time steps 1-39\n",
      "  Testing:  time steps 40-49\n",
      "\n",
      "Temporal split statistics:\n",
      "  Training nodes: 35380\n",
      "  Test nodes:     11184\n",
      "\n",
      "Temporal training set:\n",
      "  Illicit: 3909 (11.0%)\n",
      "  Licit:   31471 (89.0%)\n",
      "\n",
      "Temporal test set:\n",
      "  Illicit: 636 (5.7%)\n",
      "  Licit:   10548 (94.3%)\n"
     ]
    }
   ],
   "source": [
    "# Create temporal train/test split: 80-20 based on time steps\n",
    "# Time steps 1-49, so 80% = first 39 time steps for training, last 10 for testing\n",
    "split_time_step = int(49 * 0.8)  # 39\n",
    "\n",
    "print(f\"Temporal split at time step {split_time_step}\")\n",
    "print(f\"  Training: time steps 1-{split_time_step}\")\n",
    "print(f\"  Testing:  time steps {split_time_step+1}-49\")\n",
    "\n",
    "# Create temporal masks (only for labeled nodes)\n",
    "train_mask_temporal = torch.zeros(len(y), dtype=torch.bool)\n",
    "test_mask_temporal = torch.zeros(len(y), dtype=torch.bool)\n",
    "\n",
    "for idx in range(len(y)):\n",
    "    if y[idx] > 0:  # Only labeled nodes\n",
    "        ts = time_steps[idx]\n",
    "        if ts <= split_time_step:\n",
    "            train_mask_temporal[idx] = True\n",
    "        else:\n",
    "            test_mask_temporal[idx] = True\n",
    "\n",
    "print(f\"\\nTemporal split statistics:\")\n",
    "print(f\"  Training nodes: {train_mask_temporal.sum()}\")\n",
    "print(f\"  Test nodes:     {test_mask_temporal.sum()}\")\n",
    "\n",
    "# Check class distribution in temporal split\n",
    "train_labels_temporal = y[train_mask_temporal]\n",
    "test_labels_temporal = y[test_mask_temporal]\n",
    "\n",
    "print(f\"\\nTemporal training set:\")\n",
    "print(f\"  Illicit: {(train_labels_temporal == 1).sum()} ({(train_labels_temporal == 1).sum()/len(train_labels_temporal)*100:.1f}%)\")\n",
    "print(f\"  Licit:   {(train_labels_temporal == 2).sum()} ({(train_labels_temporal == 2).sum()/len(train_labels_temporal)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nTemporal test set:\")\n",
    "print(f\"  Illicit: {(test_labels_temporal == 1).sum()} ({(test_labels_temporal == 1).sum()/len(test_labels_temporal)*100:.1f}%)\")\n",
    "print(f\"  Licit:   {(test_labels_temporal == 2).sum()} ({(test_labels_temporal == 2).sum()/len(test_labels_temporal)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "rdvaim0zpgm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal model class weights:\n",
      "  Class 0 (Unknown): 1.0000\n",
      "  Class 1 (Illicit):  4.5255\n",
      "  Class 2 (Licit):    0.5621\n",
      "  Weight ratio (Illicit/Licit): 8.05x\n"
     ]
    }
   ],
   "source": [
    "# Initialize new model for temporal experiment\n",
    "model_temporal = GCNFraudDetector(in_features=x.shape[1], hidden=64, out_classes=3, dropout=0.5)\n",
    "model_temporal = model_temporal.to(device)\n",
    "\n",
    "# Move temporal masks to device\n",
    "train_mask_temporal = train_mask_temporal.to(device)\n",
    "test_mask_temporal = test_mask_temporal.to(device)\n",
    "\n",
    "# Calculate class weights for temporal training set\n",
    "train_labels_temp = y[train_mask_temporal]\n",
    "n_illicit_temp = (train_labels_temp == 1).sum().float()\n",
    "n_licit_temp = (train_labels_temp == 2).sum().float()\n",
    "total_temp = train_labels_temp.shape[0]\n",
    "\n",
    "weight_illicit_temp = total_temp / (2.0 * n_illicit_temp)\n",
    "weight_licit_temp = total_temp / (2.0 * n_licit_temp)\n",
    "class_weights_temporal = torch.tensor([1.0, weight_illicit_temp, weight_licit_temp], dtype=torch.float).to(device)\n",
    "\n",
    "print(\"Temporal model class weights:\")\n",
    "print(f\"  Class 0 (Unknown): {class_weights_temporal[0]:.4f}\")\n",
    "print(f\"  Class 1 (Illicit):  {class_weights_temporal[1]:.4f}\")\n",
    "print(f\"  Class 2 (Licit):    {class_weights_temporal[2]:.4f}\")\n",
    "print(f\"  Weight ratio (Illicit/Licit): {class_weights_temporal[1]/class_weights_temporal[2]:.2f}x\")\n",
    "\n",
    "optimizer_temporal = torch.optim.Adam(model_temporal.parameters(), lr=0.01)\n",
    "criterion_temporal = torch.nn.CrossEntropyLoss(weight=class_weights_temporal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fimkscpntfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GCN with Temporal Split...\n",
      "Epoch 010, Loss: 0.4990, Train Acc: 0.7701, Test Acc: 0.5787\n",
      "Epoch 020, Loss: 0.4125, Train Acc: 0.8417, Test Acc: 0.7570\n",
      "Epoch 030, Loss: 0.3634, Train Acc: 0.8550, Test Acc: 0.7658\n",
      "Epoch 040, Loss: 0.3280, Train Acc: 0.8646, Test Acc: 0.7572\n",
      "Epoch 050, Loss: 0.3045, Train Acc: 0.8780, Test Acc: 0.8063\n",
      "\n",
      "Temporal training completed!\n"
     ]
    }
   ],
   "source": [
    "# Training functions for temporal model\n",
    "def train_temporal():\n",
    "    model_temporal.train()\n",
    "    optimizer_temporal.zero_grad()\n",
    "    out = model_temporal(x, edge_index)\n",
    "    loss = criterion_temporal(out[train_mask_temporal], y[train_mask_temporal])\n",
    "    loss.backward()\n",
    "    optimizer_temporal.step()\n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_temporal(mask):\n",
    "    model_temporal.eval()\n",
    "    out = model_temporal(x, edge_index)\n",
    "    pred = out.argmax(dim=1)\n",
    "    correct = pred[mask] == y[mask]\n",
    "    acc = int(correct.sum()) / int(mask.sum())\n",
    "    return acc, pred[mask].cpu(), out[mask].cpu()\n",
    "\n",
    "# Training loop for temporal model\n",
    "print(\"Training GCN with Temporal Split...\")\n",
    "for epoch in range(1, 51):\n",
    "    loss = train_temporal()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        train_acc, _, _ = test_temporal(train_mask_temporal)\n",
    "        test_acc, _, _ = test_temporal(test_mask_temporal)\n",
    "        print(f'Epoch {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "print(\"\\nTemporal training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fmo5ydvyarb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "TEMPORAL SPLIT - FINAL EVALUATION METRICS\n",
      "==================================================\n",
      "Accuracy:  80.63%\n",
      "Precision: 17.61%\n",
      "Recall:    65.41%\n",
      "F1 Score:  27.75%\n",
      "AUC-ROC:   0.8271\n",
      "PR-AUC:    0.3676\n",
      "RMSE:      0.4401\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Temporal model evaluation\n",
    "_, test_pred_temporal, test_out_temporal = test_temporal(test_mask_temporal)\n",
    "test_labels_temporal = y[test_mask_temporal].cpu().numpy()\n",
    "\n",
    "# Convert to binary classification\n",
    "binary_pred_temporal = (test_pred_temporal.numpy() == 1).astype(int)\n",
    "binary_labels_temporal = (test_labels_temporal == 1).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy_temporal = accuracy_score(binary_labels_temporal, binary_pred_temporal)\n",
    "precision_temporal = precision_score(binary_labels_temporal, binary_pred_temporal, zero_division=0)\n",
    "recall_temporal = recall_score(binary_labels_temporal, binary_pred_temporal, zero_division=0)\n",
    "f1_temporal = f1_score(binary_labels_temporal, binary_pred_temporal, zero_division=0)\n",
    "\n",
    "# Get probabilities\n",
    "test_probs_temporal = F.softmax(test_out_temporal, dim=1)[:, 1].numpy()\n",
    "auc_roc_temporal = roc_auc_score(binary_labels_temporal, test_probs_temporal)\n",
    "pr_auc_temporal = average_precision_score(binary_labels_temporal, test_probs_temporal)\n",
    "\n",
    "# RMSE\n",
    "rmse_temporal = np.sqrt(mean_squared_error(binary_labels_temporal, binary_pred_temporal))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TEMPORAL SPLIT - FINAL EVALUATION METRICS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Accuracy:  {accuracy_temporal*100:.2f}%\")\n",
    "print(f\"Precision: {precision_temporal*100:.2f}%\")\n",
    "print(f\"Recall:    {recall_temporal*100:.2f}%\")\n",
    "print(f\"F1 Score:  {f1_temporal*100:.2f}%\")\n",
    "print(f\"AUC-ROC:   {auc_roc_temporal:.4f}\")\n",
    "print(f\"PR-AUC:    {pr_auc_temporal:.4f}\")\n",
    "print(f\"RMSE:      {rmse_temporal:.4f}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "p53vhxu2gj",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "TEMPORAL SPLIT - DIAGNOSTIC ANALYSIS\n",
      "==================================================\n",
      "\n",
      "1. Test Set Class Distribution:\n",
      "   Illicit: 636\n",
      "   Licit:   10548\n",
      "\n",
      "2. Model Predictions:\n",
      "   Predicted Licit (0):   8822\n",
      "   Predicted Illicit (1): 2362\n",
      "\n",
      "3. Confusion Matrix (Licit=0, Illicit=1):\n",
      "   [[TN FP]\n",
      "    [FN TP]]\n",
      "   [[8602 1946]\n",
      " [ 220  416]]\n",
      "\n",
      "   True Negatives (correctly predicted Licit):   8602\n",
      "   False Positives (Licit predicted as Illicit):  1946\n",
      "   False Negatives (Illicit predicted as Licit):  220\n",
      "   True Positives (correctly predicted Illicit):  416\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Temporal model diagnostic analysis\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TEMPORAL SPLIT - DIAGNOSTIC ANALYSIS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\n1. Test Set Class Distribution:\")\n",
    "print(f\"   Illicit: {sum(binary_labels_temporal == 1)}\")\n",
    "print(f\"   Licit:   {sum(binary_labels_temporal == 0)}\")\n",
    "\n",
    "print(\"\\n2. Model Predictions:\")\n",
    "print(f\"   Predicted Licit (0):   {sum(binary_pred_temporal == 0)}\")\n",
    "print(f\"   Predicted Illicit (1): {sum(binary_pred_temporal == 1)}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm_temporal = confusion_matrix(binary_labels_temporal, binary_pred_temporal)\n",
    "print(\"\\n3. Confusion Matrix (Licit=0, Illicit=1):\")\n",
    "print(\"   [[TN FP]\")\n",
    "print(\"    [FN TP]]\")\n",
    "print(f\"   {cm_temporal}\")\n",
    "print(f\"\\n   True Negatives (correctly predicted Licit):   {cm_temporal[0,0]}\")\n",
    "print(f\"   False Positives (Licit predicted as Illicit):  {cm_temporal[0,1]}\")\n",
    "print(f\"   False Negatives (Illicit predicted as Licit):  {cm_temporal[1,0]}\")\n",
    "print(f\"   True Positives (correctly predicted Illicit):  {cm_temporal[1,1]}\")\n",
    "\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
