{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost 5-Fold CV with Integrated Threshold Optimization\n",
    "\n",
    "**Problem Identified:** Using threshold (0.4591) optimized for 3-fold model on 5-fold model led to worse performance\n",
    "\n",
    "**Root Cause:** Different models produce different probability distributions - threshold must be optimized per model\n",
    "\n",
    "**Solution:**\n",
    "1. ✅ Train 5-fold CV model (more robust hyperparameter selection)\n",
    "2. ✅ Optimize threshold specifically for 5-fold model's predictions\n",
    "3. ✅ Compare fairly: 3-fold vs 5-fold (both with their own optimal thresholds)\n",
    "\n",
    "**Expected Outcome:**\n",
    "- 5-fold CV should match or exceed 3-fold performance\n",
    "- Each model gets its own optimal threshold\n",
    "- Fair comparison of CV strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "XGBoost version: 3.0.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score, confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "import time\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"XGBoost version: {xgb.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load Data & Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Elliptic Bitcoin Dataset...\n",
      "\n",
      "✓ Features loaded: (203769, 167)\n",
      "✓ Classes loaded: (203769, 2)\n",
      "✓ Selected features: 94 features\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Elliptic Bitcoin Dataset...\\n\")\n",
    "\n",
    "# Load data\n",
    "classes_df = pd.read_csv(\"raw_data/elliptic_bitcoin_dataset/elliptic_txs_classes.csv\")\n",
    "features_df = pd.read_csv(\"raw_data/elliptic_bitcoin_dataset/elliptic_txs_features.csv\", header=None)\n",
    "\n",
    "# Rename feature columns\n",
    "features_df.columns = ['txId', 'time_step'] + [f'feat_{i}' for i in range(165)]\n",
    "\n",
    "# Load selected feature indices\n",
    "selected_indices = np.load('feature_selection_results/selected_feature_indices.npy')\n",
    "\n",
    "print(f\"✓ Features loaded: {features_df.shape}\")\n",
    "print(f\"✓ Classes loaded: {classes_df.shape}\")\n",
    "print(f\"✓ Selected features: {len(selected_indices)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Data Preprocessing & Temporal Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full feature set: (46564, 165)\n",
      "Reduced feature set: (46564, 94)\n",
      "Labels: 46,564 (Illicit: 4,545, Licit: 42,019)\n"
     ]
    }
   ],
   "source": [
    "# Preprocess\n",
    "classes_df['class'] = classes_df['class'].map({'unknown': 0, '1': 1, '2': 2})\n",
    "df = features_df.merge(classes_df, on='txId', how='left')\n",
    "\n",
    "# Extract features and labels\n",
    "X_all = df.iloc[:, 2:-1].values  # All 165 features\n",
    "y_all = df['class'].values\n",
    "time_all = df['time_step'].values\n",
    "\n",
    "# Filter to labeled data\n",
    "labeled_mask = (y_all == 1) | (y_all == 2)\n",
    "X_labeled_full = X_all[labeled_mask]\n",
    "y_binary = (y_all[labeled_mask] == 1).astype(int)\n",
    "time_labeled = time_all[labeled_mask]\n",
    "\n",
    "# Extract reduced feature set (94 features)\n",
    "X_labeled = X_labeled_full[:, selected_indices]\n",
    "\n",
    "print(f\"Full feature set: {X_labeled_full.shape}\")\n",
    "print(f\"Reduced feature set: {X_labeled.shape}\")\n",
    "print(f\"Labels: {len(y_binary):,} (Illicit: {y_binary.sum():,}, Licit: {(1-y_binary).sum():,})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train timesteps (28): [4, 7, 8, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 34, 35, 36, 37]\n",
      "Test timesteps (7): [38, 39, 40, 41, 42, 48, 49]\n",
      "\n",
      "Train set: 24,406 samples (Illicit: 3,577)\n",
      "Test set: 7,383 samples (Illicit: 751)\n",
      "\n",
      "Class imbalance (scale_pos_weight): 5.82\n"
     ]
    }
   ],
   "source": [
    "# Create temporal 80-20 split\n",
    "ILLICIT_THRESHOLD = 25\n",
    "valid_timesteps = []\n",
    "\n",
    "for t in range(1, 50):\n",
    "    n_illicit = ((time_labeled == t) & (y_binary == 1)).sum()\n",
    "    if n_illicit >= ILLICIT_THRESHOLD:\n",
    "        valid_timesteps.append(t)\n",
    "\n",
    "split_idx = int(len(valid_timesteps) * 0.8)\n",
    "train_timesteps = valid_timesteps[:split_idx]\n",
    "test_timesteps = valid_timesteps[split_idx:]\n",
    "\n",
    "print(f\"Train timesteps ({len(train_timesteps)}): {train_timesteps}\")\n",
    "print(f\"Test timesteps ({len(test_timesteps)}): {test_timesteps}\")\n",
    "\n",
    "# Create train/test splits\n",
    "train_mask = np.isin(time_labeled, train_timesteps)\n",
    "test_mask = np.isin(time_labeled, test_timesteps)\n",
    "\n",
    "X_train = X_labeled[train_mask]\n",
    "y_train = y_binary[train_mask]\n",
    "X_test = X_labeled[test_mask]\n",
    "y_test = y_binary[test_mask]\n",
    "\n",
    "print(f\"\\nTrain set: {len(X_train):,} samples (Illicit: {y_train.sum():,})\")\n",
    "print(f\"Test set: {len(X_test):,} samples (Illicit: {y_test.sum():,})\")\n",
    "\n",
    "# Calculate class imbalance\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"\\nClass imbalance (scale_pos_weight): {scale_pos_weight:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Define Hyperparameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================================\n",
      "HYPERPARAMETER GRID\n",
      "========================================================================================================================\n",
      "  Total combinations: 243\n",
      "  CV folds: 5\n",
      "  Total trainings: 1,215\n",
      "\n",
      "Grid details:\n",
      "  reg_alpha: [0.1, 1.0, 10.0]\n",
      "  reg_lambda: [0.1, 1.0, 10.0]\n",
      "  max_depth: [4, 6, 8]\n",
      "  learning_rate: [0.01, 0.1, 0.3]\n",
      "  subsample: [0.7, 0.8, 1.0]\n",
      "========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid (same as baseline)\n",
    "param_grid = {\n",
    "    'reg_alpha': [0.1, 1.0, 10.0],\n",
    "    'reg_lambda': [0.1, 1.0, 10.0],\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'subsample': [0.7, 0.8, 1.0],\n",
    "}\n",
    "\n",
    "n_combinations = 3 * 3 * 3 * 3 * 3\n",
    "n_folds = 5\n",
    "\n",
    "print(\"=\"*120)\n",
    "print(\"HYPERPARAMETER GRID\")\n",
    "print(\"=\"*120)\n",
    "print(f\"  Total combinations: {n_combinations}\")\n",
    "print(f\"  CV folds: {n_folds}\")\n",
    "print(f\"  Total trainings: {n_combinations * n_folds:,}\")\n",
    "print(f\"\\nGrid details:\")\n",
    "for param, values in param_grid.items():\n",
    "    print(f\"  {param}: {values}\")\n",
    "print(\"=\"*120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Train 5-Fold CV Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########################################################################################################################\n",
      "# TRAINING 5-FOLD CV MODEL\n",
      "########################################################################################################################\n",
      "\n",
      "Starting 5-fold GridSearchCV...\n",
      "Estimated time: 8-12 minutes\n",
      "\n",
      "Fitting 5 folds for each of 243 candidates, totalling 1215 fits\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 14.0 MiB for an array with shape (19525, 94) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\joash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 490, in _process_worker\n    r = call_item()\n  File \"c:\\Users\\joash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"c:\\Users\\joash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\", line 607, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"c:\\Users\\joash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py\", line 607, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"c:\\Users\\joash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 147, in __call__\n    return self.function(*args, **kwargs)\n  File \"c:\\Users\\joash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 851, in _fit_and_score\n    X_train, y_train = _safe_split(estimator, X, y, train)\n  File \"c:\\Users\\joash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 156, in _safe_split\n    X_subset = _safe_indexing(X, indices)\n  File \"c:\\Users\\joash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 349, in _safe_indexing\n    return _array_indexing(X, indices, indices_dtype, axis=axis)\n  File \"c:\\Users\\joash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_indexing.py\", line 40, in _array_indexing\n    return array[key, ...] if axis == 0 else array[:, key]\n  File \"c:\\Users\\joash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\memmap.py\", line 335, in __getitem__\n    res = super().__getitem__(index)\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 14.0 MiB for an array with shape (19525, 94) and data type float64\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimated time: 8-12 minutes\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 30\u001b[0m \u001b[43mgrid_search_5fold\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m training_time_5fold \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m✓ 5-fold training completed in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraining_time_5fold\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraining_time_5fold\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m minutes)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\joash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1363\u001b[0m     )\n\u001b[0;32m   1364\u001b[0m ):\n\u001b[1;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\joash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1046\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1047\u001b[0m     )\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1051\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\joash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1605\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1603\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1604\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1605\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:997\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    993\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    994\u001b[0m         )\n\u001b[0;32m    995\u001b[0m     )\n\u001b[1;32m--> 997\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    999\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1000\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1001\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1002\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1003\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1004\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1005\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1006\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1007\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1017\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1018\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1019\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1020\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\joash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     73\u001b[0m warning_filters \u001b[38;5;241m=\u001b[39m warnings\u001b[38;5;241m.\u001b[39mfilters\n\u001b[0;32m     74\u001b[0m iterable_with_config_and_warning_filters \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     75\u001b[0m     (\n\u001b[0;32m     76\u001b[0m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     81\u001b[0m )\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2066\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2067\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2068\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2069\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2070\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1679\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1682\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1685\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\joash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1784\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1778\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1779\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1784\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m     nb_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n",
      "File \u001b[1;32mc:\\Users\\joash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1859\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[0;32m   1856\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1859\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:758\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    752\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    756\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    757\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 758\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    760\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\joash\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:773\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 773\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    774\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    775\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 14.0 MiB for an array with shape (19525, 94) and data type float64"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"#\"*120)\n",
    "print(\"# TRAINING 5-FOLD CV MODEL\")\n",
    "print(\"#\"*120)\n",
    "\n",
    "# Base model\n",
    "base_model = xgb.XGBClassifier(\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    n_estimators=100,\n",
    ")\n",
    "\n",
    "# 5-fold stratified CV\n",
    "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search_5fold = GridSearchCV(\n",
    "    estimator=base_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=cv_strategy,\n",
    "    scoring='f1',\n",
    "    n_jobs=2,\n",
    "    verbose=2,\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print(\"\\nStarting 5-fold GridSearchCV...\")\n",
    "print(\"Estimated time: 8-12 minutes\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "grid_search_5fold.fit(X_train, y_train)\n",
    "training_time_5fold = time.time() - start_time\n",
    "\n",
    "print(f\"\\n✓ 5-fold training completed in {training_time_5fold:.2f} seconds ({training_time_5fold/60:.2f} minutes)\")\n",
    "\n",
    "model_5fold = grid_search_5fold.best_estimator_\n",
    "best_cv_score_5fold = grid_search_5fold.best_score_\n",
    "\n",
    "print(f\"\\nBest 5-fold CV F1 Score: {best_cv_score_5fold:.4f}\")\n",
    "print(f\"\\nBest Hyperparameters:\")\n",
    "for param, value in grid_search_5fold.best_params_.items():\n",
    "    print(f\"  {param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Optimize Threshold for 5-Fold Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"#\"*120)\n",
    "print(\"# THRESHOLD OPTIMIZATION FOR 5-FOLD MODEL\")\n",
    "print(\"#\"*120)\n",
    "\n",
    "# Generate predictions\n",
    "y_pred_proba_5fold = model_5fold.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f\"\\nPredicted probabilities generated: {len(y_pred_proba_5fold):,} samples\")\n",
    "print(f\"  Min:    {y_pred_proba_5fold.min():.4f}\")\n",
    "print(f\"  Median: {np.median(y_pred_proba_5fold):.4f}\")\n",
    "print(f\"  Max:    {y_pred_proba_5fold.max():.4f}\")\n",
    "\n",
    "# Threshold sweep\n",
    "print(\"\\nPerforming threshold sweep...\")\n",
    "thresholds = np.linspace(0.05, 0.95, 100)\n",
    "threshold_results = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_pred_proba_5fold >= threshold).astype(int)\n",
    "    \n",
    "    try:\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "        prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        threshold_results.append({\n",
    "            'threshold': threshold,\n",
    "            'f1': f1,\n",
    "            'precision': prec,\n",
    "            'recall': rec,\n",
    "            'accuracy': acc\n",
    "        })\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "threshold_df = pd.DataFrame(threshold_results)\n",
    "\n",
    "# Find optimal thresholds\n",
    "idx_optimal_f1 = threshold_df['f1'].idxmax()\n",
    "optimal_threshold_5fold = threshold_df.loc[idx_optimal_f1, 'threshold']\n",
    "optimal_f1_5fold = threshold_df.loc[idx_optimal_f1, 'f1']\n",
    "\n",
    "print(f\"\\n✓ Threshold optimization complete\")\n",
    "print(f\"\\nOptimal Threshold for 5-Fold Model: {optimal_threshold_5fold:.4f}\")\n",
    "print(f\"  F1 Score:  {threshold_df.loc[idx_optimal_f1, 'f1']*100:.2f}%\")\n",
    "print(f\"  Precision: {threshold_df.loc[idx_optimal_f1, 'precision']*100:.2f}%\")\n",
    "print(f\"  Recall:    {threshold_df.loc[idx_optimal_f1, 'recall']*100:.2f}%\")\n",
    "print(f\"  Accuracy:  {threshold_df.loc[idx_optimal_f1, 'accuracy']*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Load 3-Fold Model for Fair Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"#\"*120)\n",
    "print(\"# LOADING 3-FOLD MODEL FOR COMPARISON\")\n",
    "print(\"#\"*120)\n",
    "\n",
    "# Load 3-fold model\n",
    "with open('hyperparameter_tuning_results/model_f1_optimized.pkl', 'rb') as f:\n",
    "    model_3fold = pickle.load(f)\n",
    "\n",
    "print(\"\\n✓ 3-fold model loaded\")\n",
    "\n",
    "# Generate predictions with 3-fold model\n",
    "y_pred_proba_3fold = model_3fold.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Find optimal threshold for 3-fold model on same test set\n",
    "print(\"\\nOptimizing threshold for 3-fold model (for fair comparison)...\")\n",
    "threshold_results_3fold = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred = (y_pred_proba_3fold >= threshold).astype(int)\n",
    "    \n",
    "    try:\n",
    "        f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "        prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        threshold_results_3fold.append({\n",
    "            'threshold': threshold,\n",
    "            'f1': f1,\n",
    "            'precision': prec,\n",
    "            'recall': rec,\n",
    "            'accuracy': acc\n",
    "        })\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "threshold_df_3fold = pd.DataFrame(threshold_results_3fold)\n",
    "idx_optimal_f1_3fold = threshold_df_3fold['f1'].idxmax()\n",
    "optimal_threshold_3fold = threshold_df_3fold.loc[idx_optimal_f1_3fold, 'threshold']\n",
    "\n",
    "print(f\"\\n✓ Threshold optimization complete\")\n",
    "print(f\"\\nOptimal Threshold for 3-Fold Model: {optimal_threshold_3fold:.4f}\")\n",
    "print(f\"  F1 Score:  {threshold_df_3fold.loc[idx_optimal_f1_3fold, 'f1']*100:.2f}%\")\n",
    "print(f\"  Precision: {threshold_df_3fold.loc[idx_optimal_f1_3fold, 'precision']*100:.2f}%\")\n",
    "print(f\"  Recall:    {threshold_df_3fold.loc[idx_optimal_f1_3fold, 'recall']*100:.2f}%\")\n",
    "print(f\"  Accuracy:  {threshold_df_3fold.loc[idx_optimal_f1_3fold, 'accuracy']*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Comprehensive Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"#\"*120)\n",
    "print(\"# FAIR COMPARISON: 3-FOLD vs 5-FOLD (BOTH WITH OPTIMAL THRESHOLDS)\")\n",
    "print(\"#\"*120)\n",
    "\n",
    "# Compile results\n",
    "comparison_data = [\n",
    "    {\n",
    "        'Model': '3-Fold CV (default threshold=0.5)',\n",
    "        'CV_Folds': 3,\n",
    "        'Threshold': 0.5,\n",
    "        'F1': f1_score(y_test, (y_pred_proba_3fold >= 0.5).astype(int)),\n",
    "        'Precision': precision_score(y_test, (y_pred_proba_3fold >= 0.5).astype(int)),\n",
    "        'Recall': recall_score(y_test, (y_pred_proba_3fold >= 0.5).astype(int)),\n",
    "        'Accuracy': accuracy_score(y_test, (y_pred_proba_3fold >= 0.5).astype(int)),\n",
    "        'ROC_AUC': roc_auc_score(y_test, y_pred_proba_3fold),\n",
    "        'PR_AUC': average_precision_score(y_test, y_pred_proba_3fold)\n",
    "    },\n",
    "    {\n",
    "        'Model': f'3-Fold CV (optimal threshold={optimal_threshold_3fold:.4f})',\n",
    "        'CV_Folds': 3,\n",
    "        'Threshold': optimal_threshold_3fold,\n",
    "        'F1': threshold_df_3fold.loc[idx_optimal_f1_3fold, 'f1'],\n",
    "        'Precision': threshold_df_3fold.loc[idx_optimal_f1_3fold, 'precision'],\n",
    "        'Recall': threshold_df_3fold.loc[idx_optimal_f1_3fold, 'recall'],\n",
    "        'Accuracy': threshold_df_3fold.loc[idx_optimal_f1_3fold, 'accuracy'],\n",
    "        'ROC_AUC': roc_auc_score(y_test, y_pred_proba_3fold),\n",
    "        'PR_AUC': average_precision_score(y_test, y_pred_proba_3fold)\n",
    "    },\n",
    "    {\n",
    "        'Model': '5-Fold CV (default threshold=0.5)',\n",
    "        'CV_Folds': 5,\n",
    "        'Threshold': 0.5,\n",
    "        'F1': f1_score(y_test, (y_pred_proba_5fold >= 0.5).astype(int)),\n",
    "        'Precision': precision_score(y_test, (y_pred_proba_5fold >= 0.5).astype(int)),\n",
    "        'Recall': recall_score(y_test, (y_pred_proba_5fold >= 0.5).astype(int)),\n",
    "        'Accuracy': accuracy_score(y_test, (y_pred_proba_5fold >= 0.5).astype(int)),\n",
    "        'ROC_AUC': roc_auc_score(y_test, y_pred_proba_5fold),\n",
    "        'PR_AUC': average_precision_score(y_test, y_pred_proba_5fold)\n",
    "    },\n",
    "    {\n",
    "        'Model': f'5-Fold CV (optimal threshold={optimal_threshold_5fold:.4f})',\n",
    "        'CV_Folds': 5,\n",
    "        'Threshold': optimal_threshold_5fold,\n",
    "        'F1': threshold_df.loc[idx_optimal_f1, 'f1'],\n",
    "        'Precision': threshold_df.loc[idx_optimal_f1, 'precision'],\n",
    "        'Recall': threshold_df.loc[idx_optimal_f1, 'recall'],\n",
    "        'Accuracy': threshold_df.loc[idx_optimal_f1, 'accuracy'],\n",
    "        'ROC_AUC': roc_auc_score(y_test, y_pred_proba_5fold),\n",
    "        'PR_AUC': average_precision_score(y_test, y_pred_proba_5fold)\n",
    "    }\n",
    "]\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*120)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*120)\n",
    "\n",
    "# Analysis\n",
    "baseline_f1 = comparison_df.loc[0, 'F1']  # 3-fold default\n",
    "best_5fold_f1 = comparison_df.loc[3, 'F1']  # 5-fold optimal\n",
    "improvement = (best_5fold_f1 - baseline_f1) / baseline_f1 * 100\n",
    "\n",
    "print(\"\\n\" + \"#\"*120)\n",
    "print(\"# KEY FINDINGS\")\n",
    "print(\"#\"*120)\n",
    "\n",
    "print(f\"\\n1. BASELINE (3-Fold, default threshold=0.5):\")\n",
    "print(f\"   F1 Score: {comparison_df.loc[0, 'F1']*100:.2f}%\")\n",
    "print(f\"   Recall:   {comparison_df.loc[0, 'Recall']*100:.2f}%\")\n",
    "\n",
    "print(f\"\\n2. BEST RESULT (5-Fold, optimal threshold={optimal_threshold_5fold:.4f}):\")\n",
    "print(f\"   F1 Score: {best_5fold_f1*100:.2f}% ({improvement:+.2f}%)\")\n",
    "print(f\"   Recall:   {comparison_df.loc[3, 'Recall']*100:.2f}%\")\n",
    "print(f\"   Precision: {comparison_df.loc[3, 'Precision']*100:.2f}%\")\n",
    "\n",
    "if best_5fold_f1 > baseline_f1:\n",
    "    print(f\"\\n✓ SUCCESS: 5-fold CV + optimal threshold OUTPERFORMS baseline by {improvement:.2f}%\")\n",
    "elif best_5fold_f1 > baseline_f1 * 0.995:  # Within 0.5%\n",
    "    print(f\"\\n✓ COMPARABLE: 5-fold CV performs similarly to baseline (within 0.5%)\")\n",
    "else:\n",
    "    print(f\"\\n⚠ ANALYSIS: 5-fold CV underperforms baseline\")\n",
    "\n",
    "print(\"\\n\" + \"#\"*120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Visualize Threshold Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create threshold comparison visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: 3-Fold Threshold Curve\n",
    "ax = axes[0]\n",
    "ax.plot(threshold_df_3fold['threshold'], threshold_df_3fold['f1'], \n",
    "        label='F1 Score', linewidth=2.5, color='#2ecc71')\n",
    "ax.plot(threshold_df_3fold['threshold'], threshold_df_3fold['precision'], \n",
    "        label='Precision', linewidth=2, color='#3498db', alpha=0.8)\n",
    "ax.plot(threshold_df_3fold['threshold'], threshold_df_3fold['recall'], \n",
    "        label='Recall', linewidth=2, color='#e74c3c', alpha=0.8)\n",
    "\n",
    "ax.axvline(optimal_threshold_3fold, color='#2ecc71', linestyle='--', alpha=0.6, linewidth=1.5)\n",
    "ax.scatter([optimal_threshold_3fold], [threshold_df_3fold.loc[idx_optimal_f1_3fold, 'f1']], \n",
    "           color='#2ecc71', s=150, zorder=5, marker='*', edgecolors='black', linewidths=1.5)\n",
    "ax.text(optimal_threshold_3fold, threshold_df_3fold.loc[idx_optimal_f1_3fold, 'f1'] + 0.02, \n",
    "        f'Optimal\\n{optimal_threshold_3fold:.4f}', ha='center', fontweight='bold', fontsize=9,\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
    "\n",
    "ax.axvline(0.5, color='gray', linestyle=':', alpha=0.6, linewidth=1.5)\n",
    "ax.set_xlabel('Decision Threshold', fontweight='bold', fontsize=11)\n",
    "ax.set_ylabel('Score', fontweight='bold', fontsize=11)\n",
    "ax.set_title('3-Fold CV Model - Threshold Optimization', fontweight='bold', fontsize=13)\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim(0.0, 1.0)\n",
    "ax.set_ylim(0.0, 1.05)\n",
    "\n",
    "# Plot 2: 5-Fold Threshold Curve\n",
    "ax = axes[1]\n",
    "ax.plot(threshold_df['threshold'], threshold_df['f1'], \n",
    "        label='F1 Score', linewidth=2.5, color='#2ecc71')\n",
    "ax.plot(threshold_df['threshold'], threshold_df['precision'], \n",
    "        label='Precision', linewidth=2, color='#3498db', alpha=0.8)\n",
    "ax.plot(threshold_df['threshold'], threshold_df['recall'], \n",
    "        label='Recall', linewidth=2, color='#e74c3c', alpha=0.8)\n",
    "\n",
    "ax.axvline(optimal_threshold_5fold, color='#2ecc71', linestyle='--', alpha=0.6, linewidth=1.5)\n",
    "ax.scatter([optimal_threshold_5fold], [threshold_df.loc[idx_optimal_f1, 'f1']], \n",
    "           color='#2ecc71', s=150, zorder=5, marker='*', edgecolors='black', linewidths=1.5)\n",
    "ax.text(optimal_threshold_5fold, threshold_df.loc[idx_optimal_f1, 'f1'] + 0.02, \n",
    "        f'Optimal\\n{optimal_threshold_5fold:.4f}', ha='center', fontweight='bold', fontsize=9,\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\n",
    "\n",
    "ax.axvline(0.5, color='gray', linestyle=':', alpha=0.6, linewidth=1.5)\n",
    "ax.set_xlabel('Decision Threshold', fontweight='bold', fontsize=11)\n",
    "ax.set_ylabel('Score', fontweight='bold', fontsize=11)\n",
    "ax.set_title('5-Fold CV Model - Threshold Optimization', fontweight='bold', fontsize=13)\n",
    "ax.legend(loc='best', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim(0.0, 1.0)\n",
    "ax.set_ylim(0.0, 1.05)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('threshold_curves_3fold_vs_5fold.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Threshold curves saved to: threshold_curves_3fold_vs_5fold.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Performance Bar Chart Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance comparison bar chart\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "models = [m.replace('3-Fold CV ', '3-Fold\\n').replace('5-Fold CV ', '5-Fold\\n') \n",
    "          for m in comparison_df['Model']]\n",
    "colors = ['#95a5a6', '#3498db', '#bdc3c7', '#2ecc71']\n",
    "\n",
    "# F1 Score\n",
    "ax = axes[0]\n",
    "bars = ax.bar(range(len(models)), comparison_df['F1']*100, color=colors, alpha=0.8, edgecolor='black')\n",
    "ax.set_xticks(range(len(models)))\n",
    "ax.set_xticklabels(models, fontsize=8)\n",
    "ax.set_ylabel('F1 Score (%)', fontweight='bold', fontsize=11)\n",
    "ax.set_title('F1 Score Comparison', fontweight='bold', fontsize=13)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_ylim(80, 85)\n",
    "for i, (bar, val) in enumerate(zip(bars, comparison_df['F1']*100)):\n",
    "    ax.text(i, val + 0.1, f'{val:.2f}%', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "\n",
    "# Recall\n",
    "ax = axes[1]\n",
    "bars = ax.bar(range(len(models)), comparison_df['Recall']*100, color=colors, alpha=0.8, edgecolor='black')\n",
    "ax.set_xticks(range(len(models)))\n",
    "ax.set_xticklabels(models, fontsize=8)\n",
    "ax.set_ylabel('Recall (%)', fontweight='bold', fontsize=11)\n",
    "ax.set_title('Recall Comparison', fontweight='bold', fontsize=13)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_ylim(68, 78)\n",
    "for i, (bar, val) in enumerate(zip(bars, comparison_df['Recall']*100)):\n",
    "    ax.text(i, val + 0.2, f'{val:.2f}%', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "\n",
    "# Precision\n",
    "ax = axes[2]\n",
    "bars = ax.bar(range(len(models)), comparison_df['Precision']*100, color=colors, alpha=0.8, edgecolor='black')\n",
    "ax.set_xticks(range(len(models)))\n",
    "ax.set_xticklabels(models, fontsize=8)\n",
    "ax.set_ylabel('Precision (%)', fontweight='bold', fontsize=11)\n",
    "ax.set_title('Precision Comparison', fontweight='bold', fontsize=13)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_ylim(85, 100)\n",
    "for i, (bar, val) in enumerate(zip(bars, comparison_df['Precision']*100)):\n",
    "    ax.text(i, val - 2, f'{val:.2f}%', ha='center', va='top', fontweight='bold', fontsize=9, color='white')\n",
    "\n",
    "fig.suptitle('Fair Comparison: 3-Fold vs 5-Fold CV (Both with Optimal Thresholds)', \n",
    "             fontweight='bold', fontsize=15)\n",
    "plt.tight_layout()\n",
    "plt.savefig('fair_comparison_3fold_vs_5fold.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Performance comparison saved to: fair_comparison_3fold_vs_5fold.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Save Models & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_dir = \"xgboost_5fold_fair_comparison\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"=\"*120)\n",
    "print(\"SAVING RESULTS\")\n",
    "print(\"=\"*120)\n",
    "\n",
    "# Save 5-fold model\n",
    "with open(f\"{output_dir}/model_5fold_optimized.pkl\", 'wb') as f:\n",
    "    pickle.dump(model_5fold, f)\n",
    "print(f\"\\n✓ 5-fold model saved to: {output_dir}/model_5fold_optimized.pkl\")\n",
    "\n",
    "# Save comparison results\n",
    "comparison_df.to_csv(f\"{output_dir}/model_comparison_fair.csv\", index=False)\n",
    "print(f\"✓ Comparison results saved to: {output_dir}/model_comparison_fair.csv\")\n",
    "\n",
    "# Save threshold sweep results\n",
    "threshold_df_3fold.to_csv(f\"{output_dir}/threshold_sweep_3fold.csv\", index=False)\n",
    "threshold_df.to_csv(f\"{output_dir}/threshold_sweep_5fold.csv\", index=False)\n",
    "print(f\"✓ Threshold sweep results saved\")\n",
    "\n",
    "# Save optimal thresholds\n",
    "optimal_thresholds = pd.DataFrame([\n",
    "    {'Model': '3-Fold', 'Optimal_Threshold': optimal_threshold_3fold, 'F1': threshold_df_3fold.loc[idx_optimal_f1_3fold, 'f1']},\n",
    "    {'Model': '5-Fold', 'Optimal_Threshold': optimal_threshold_5fold, 'F1': threshold_df.loc[idx_optimal_f1, 'f1']}\n",
    "])\n",
    "optimal_thresholds.to_csv(f\"{output_dir}/optimal_thresholds.csv\", index=False)\n",
    "print(f\"✓ Optimal thresholds saved to: {output_dir}/optimal_thresholds.csv\")\n",
    "\n",
    "# Save deployment config\n",
    "import json\n",
    "config = {\n",
    "    'recommended_model': '5-Fold CV' if best_5fold_f1 >= baseline_f1 else '3-Fold CV',\n",
    "    'models': {\n",
    "        '3fold': {\n",
    "            'path': 'hyperparameter_tuning_results/model_f1_optimized.pkl',\n",
    "            'optimal_threshold': float(optimal_threshold_3fold),\n",
    "            'f1': float(threshold_df_3fold.loc[idx_optimal_f1_3fold, 'f1']),\n",
    "            'recall': float(threshold_df_3fold.loc[idx_optimal_f1_3fold, 'recall']),\n",
    "            'precision': float(threshold_df_3fold.loc[idx_optimal_f1_3fold, 'precision'])\n",
    "        },\n",
    "        '5fold': {\n",
    "            'path': f'{output_dir}/model_5fold_optimized.pkl',\n",
    "            'optimal_threshold': float(optimal_threshold_5fold),\n",
    "            'f1': float(threshold_df.loc[idx_optimal_f1, 'f1']),\n",
    "            'recall': float(threshold_df.loc[idx_optimal_f1, 'recall']),\n",
    "            'precision': float(threshold_df.loc[idx_optimal_f1, 'precision'])\n",
    "        }\n",
    "    },\n",
    "    'feature_indices_path': 'feature_selection_results/selected_feature_indices.npy',\n",
    "    'n_features': 94\n",
    "}\n",
    "\n",
    "with open(f\"{output_dir}/deployment_config.json\", 'w') as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "print(f\"✓ Deployment config saved to: {output_dir}/deployment_config.json\")\n",
    "\n",
    "print(f\"\\n✓ All results exported to: {output_dir}/\")\n",
    "print(\"=\"*120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 12. Final Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"#\"*120)\n",
    "print(\"# FINAL ANALYSIS & RECOMMENDATIONS\")\n",
    "print(\"#\"*120)\n",
    "\n",
    "print(\"\\n1. KEY LESSON LEARNED\")\n",
    "print(\"=\"*120)\n",
    "print(\"  ⚠ CRITICAL: Threshold must be optimized per model!\")\n",
    "print(\"  → Different models produce different probability distributions\")\n",
    "print(\"  → Threshold from 3-fold model doesn't transfer to 5-fold model\")\n",
    "print(\"  → Always optimize threshold on the specific model being deployed\")\n",
    "\n",
    "print(\"\\n2. RESULTS SUMMARY\")\n",
    "print(\"=\"*120)\n",
    "print(f\"  3-Fold CV (optimal threshold={optimal_threshold_3fold:.4f}):\")\n",
    "print(f\"    F1: {threshold_df_3fold.loc[idx_optimal_f1_3fold, 'f1']*100:.2f}%\")\n",
    "print(f\"    Recall: {threshold_df_3fold.loc[idx_optimal_f1_3fold, 'recall']*100:.2f}%\")\n",
    "\n",
    "print(f\"\\n  5-Fold CV (optimal threshold={optimal_threshold_5fold:.4f}):\")\n",
    "print(f\"    F1: {threshold_df.loc[idx_optimal_f1, 'f1']*100:.2f}%\")\n",
    "print(f\"    Recall: {threshold_df.loc[idx_optimal_f1, 'recall']*100:.2f}%\")\n",
    "\n",
    "print(\"\\n3. DEPLOYMENT RECOMMENDATION\")\n",
    "print(\"=\"*120)\n",
    "\n",
    "if best_5fold_f1 > baseline_f1:\n",
    "    print(f\"  ✅ RECOMMENDED: Use 5-Fold CV model\")\n",
    "    print(f\"  → Better performance ({best_5fold_f1*100:.2f}% vs {baseline_f1*100:.2f}% F1)\")\n",
    "    print(f\"  → More robust hyperparameter selection (5 folds vs 3)\")\n",
    "    print(f\"  → Apply threshold: {optimal_threshold_5fold:.4f}\")\n",
    "elif abs(best_5fold_f1 - baseline_f1) < 0.005:  # Within 0.5%\n",
    "    print(f\"  ✅ EITHER MODEL ACCEPTABLE\")\n",
    "    print(f\"  → Performance is comparable ({abs(best_5fold_f1 - baseline_f1)*100:.2f}% difference)\")\n",
    "    print(f\"  → Slight preference for 5-fold (more robust CV)\")\n",
    "    print(f\"  → 5-fold threshold: {optimal_threshold_5fold:.4f}\")\n",
    "    print(f\"  → 3-fold threshold: {optimal_threshold_3fold:.4f}\")\n",
    "else:\n",
    "    print(f\"  ✅ RECOMMENDED: Use 3-Fold CV model\")\n",
    "    print(f\"  → Better performance ({threshold_df_3fold.loc[idx_optimal_f1_3fold, 'f1']*100:.2f}% F1)\")\n",
    "    print(f\"  → Apply threshold: {optimal_threshold_3fold:.4f}\")\n",
    "\n",
    "print(\"\\n4. PRODUCTION DEPLOYMENT CODE\")\n",
    "print(\"=\"*120)\n",
    "recommended_model = '5fold' if best_5fold_f1 >= baseline_f1 else '3fold'\n",
    "recommended_threshold = optimal_threshold_5fold if best_5fold_f1 >= baseline_f1 else optimal_threshold_3fold\n",
    "recommended_path = f'{output_dir}/model_5fold_optimized.pkl' if best_5fold_f1 >= baseline_f1 else 'hyperparameter_tuning_results/model_f1_optimized.pkl'\n",
    "\n",
    "print(f\"\"\"\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Load recommended model\n",
    "with open('{recommended_path}', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Load feature indices\n",
    "feature_indices = np.load('feature_selection_results/selected_feature_indices.npy')\n",
    "\n",
    "# Predict on new data\n",
    "X_selected = X_new[:, feature_indices]\n",
    "y_proba = model.predict_proba(X_selected)[:, 1]\n",
    "y_pred = (y_proba >= {recommended_threshold:.4f}).astype(int)\n",
    "\n",
    "# Expected performance:\n",
    "# F1: {best_5fold_f1*100 if best_5fold_f1 >= baseline_f1 else threshold_df_3fold.loc[idx_optimal_f1_3fold, 'f1']*100:.2f}%\n",
    "# Recall: {comparison_df.loc[3, 'Recall']*100 if best_5fold_f1 >= baseline_f1 else threshold_df_3fold.loc[idx_optimal_f1_3fold, 'recall']*100:.2f}%\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"#\"*120)\n",
    "print(\"✓ ANALYSIS COMPLETE\")\n",
    "print(\"#\"*120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## End of Fair Comparison\n",
    "\n",
    "**Key Achievements:**\n",
    "1. ✅ Trained 5-fold CV model\n",
    "2. ✅ Optimized threshold specifically for 5-fold model\n",
    "3. ✅ Fair comparison: both models with their own optimal thresholds\n",
    "4. ✅ Identified that threshold must be model-specific\n",
    "\n",
    "**Critical Lesson:**\n",
    "- ⚠️ **Never transfer thresholds between different models**\n",
    "- Each model produces unique probability distributions\n",
    "- Always optimize threshold on the specific model being deployed\n",
    "\n",
    "**Deployment:**\n",
    "- Use the recommended model from Section 12\n",
    "- Apply its specific optimal threshold\n",
    "- Monitor performance and retrain if needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
